% !TeX encoding   = UTF-8
\documentclass[12pt]{article}

\usepackage{sbc-template}

\usepackage{graphicx,url}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}	%Package para figuras
\usepackage{tabularx}
\usepackage{multirow} 
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{makeidx}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{epsfig}
\usepackage{adjustbox}
\usepackage{array}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
%\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}

     
\sloppy

\title{Projeto e Análise de Algoritmos\\ Trabalho Prático 1 - Paradigmas}

\author{Vagner Clementino\inst{1}}

\address{Departamento de Ciência da Computação\\
	   Universidade Federal de Minas Gerais (UFMG)\\  
  \email{vagnercs@dcc.ufmg.br}
}

\begin{document} 

\maketitle

%\begin{abstract}
%  This meta-paper describes the style to be used in articles and short papers
%  for SBC conferences. For papers in English, you should add just an abstract
%  while for the papers in Portuguese, we also ask for an abstract in
%  Portuguese (``resumo''). In both cases, abstracts should not have more than
%  10 lines and must be in the first page of the paper.
%\end{abstract}
     
%\begin{resumo} 
%TO DO
%\end{resumo}


\section{Introdução}
\label{sec:intro}

Apesar da crença, um cérebro maior não indica maior inteligência. Um contraexemplo bastante conhecido é Albert Einsten, cujo cérebro possuía um volume que não era maior do que o da média dos indivíduos. Com a melhoria das imagens de ressonância magnética (IRM), diversos estudos vêm sendo proposto com o objetivo de correlacionar o \textit{volume} do cérebro com o \textit{Quociente de Inteligência} (QI). Um estudo utilizando imagens concluiu que a correlação entre QI e o volume do cérebro é consistente, todavia, as correlações são fracas, e não há como comprovar uma relação direta. Em síntese: ser um \textit{``cabeção"} não é indicativo de inteligência.

A fim de refutar de vez esta crença, este trabalho se propõem em analisar os dados de \emph{peso} e \emph{QI} de um determinada população, com o objetivo de encontrar o maior número de pessoas cujo o peso do seu cérebro é menor, contudo, com um QI maior. O problema será formalmente definido na Seção \ref{sec:definicao}{}.

Este documento está estruturado como segue. A Seção \ref{sec:definicao} define formalmente o problema, fazendo uma relação do mesmo com o problema da \textit{Longest increasing subsequence}{}; a Seção \ref{sec:solucoes} apresenta as três soluções propostas para resolver o problema: \textsc{Força Bruta} (subseção \ref{subsec:forca_bruta}{}), \textsc{Gulosa} (subseção \ref{subsec:guloso}) e \textsc{Programação Dinâmica} (subseção \ref{subsec:pd}); a Seção \ref{sec:experimentos}{} faz uma discussão sobre resultados os experimentais de cada solução; a Seção \ref{sec:conclusao} conclui o trabalho.

\section{Definição Formal do Problema}
\label{sec:definicao}

O problema pode ser definido formalmente da seguinte forma. Dados $C=\langle c_1, c_2, \ldots, c_n\rangle$ um conjunto de indivíduos de tamanho $n$, bem como $P=\langle p_1, p_2, \ldots, p_n\rangle$ e $Q=\langle q_1, q_2, \ldots, q_n\rangle$, onde $p_i$ e $q_i$ representa, respectivamente, o peso e o QI do i-ésimo indivíduo. O problema consiste em encontrar o subconjunto $S \subseteq C$ tal que para todo $s_i,s_j\in S $ onde $ i < j$ $ p_i < p_j$  \textbf{e} $q_i > q_j$. Além disso, $|S|$ deve ser \textit{máximo}.

O problema proposto neste trabalho pode ser facilmente mapeado para um bem conhecido problema de otimização denominado \textit{Longest Increasing Subsequence - LIS}{}\cite{knuth2013art}{}. Para tanto, basta ordenar um dos conjuntos $P$ ou $Q$ de forma crescente ou decrescente. Por exemplo, caso o conjunto $P$ seja ordenado de forma decrescente, o problema se transforma em encontrar a maior \textit{LIS} no novo conjunto $Q^{'}$ que foi gerado pela ordenação de $P$.\footnote{Considera-se que para toda posição i em $P$ e $Q$ represente os dados do mesmo indivíduo}

O LIS é um problema bastante estudado e existem diversas abordagens na literatura para resolvê-lo. Este trabalho utilizou algumas destas referências para desenvolver as soluções propostas na Seção \ref{sec:solucoes}{}.

\section{Soluções propostas}
\label{sec:solucoes}

Neste trabalho foi proposto três soluções para o problema utilizando os paradigmas \textsc{Força Bruta},  \textsc{Gulosa} e \textsc{Programação Dinâmica}{}. Para cada paradigma discute-se como foi realizada a modelagem, o funcionamento do algoritmo proposto e a análise da complexidade de tempo e de espaço. A descrição dos algoritmos será feita em mais alto nível por meio de pseudocódigo.

\subsection{Força Bruta}
\label{subsec:forca_bruta}

\subsubsection{Modelagem}
\label{subsubsec:model_fb}
O paradigma de Força Bruta é o único que garantidamente encontra uma solução ótima para qualquer problema computável. Contudo, o preço que se paga por esta aplicabilidade universal é o alto custo de tempo e/ou espaço necessário. A principal característica de uma abordagem Força Bruta é que ela faz uma \textit{busca integral no espaço de soluções} \cite{Kleinberg:2005:AD:1051910}{}. Neste sentido, ao desenvolvermos um algoritmo força bruta, ele deverá listar todas as possíveis soluções para posteriormente definir a melhor entre as soluções válidas.

No contexto do problema estudado, o espaço de soluções consiste de todas as permutações dos elementos do \textit{power set} de $C$, cuja a notação é dada por $2^{C}$. Desta forma, o algoritmo a ser proposto deverá ser capaz de criar cada permutação de tamanho $1,2,\ldots, n$. Para cada permutação/solução criada deverá ser verificado se a solução é válida a fim de encontrar a melhor entre aquelas que são válidas. Na próxima subseção descreveremos o algoritmo proposto.

\subsubsection{O Algoritmo Força Bruta}
\label{subsubsec:alg_fb}

O algoritmo \ref{algo:brute_force} apresenta em alto nível a abordagem Força Bruta utilizada. Por meio do método \textsc{GENERATE-ALL-SOLUTIONS} todas as possível soluções são geradas. A partir delas a solução ótima (de maior tamanho) é encontrada e posteriormente retornada $S_{best}$. O método \textsc{IS-VALID} verifica se uma dada solução é valida verificando se cada par de item respeita as restrições do problema.

\begin{algorithm}
\SetKwFunction{ISVALID}{IS-VALID}
\SetKwFunction{GENERATEALLSOLUTIONS}{GENERATE-ALL-SOLUTIONS}
\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\KwIn{As sequências finitas $C=\langle c_1, c_2, \ldots, c_n\rangle$, $P=\langle p_1, p_2, \ldots, p_n\rangle$ e $Q=\langle q_1, q_2, \dots, q_n\rangle$}
\KwOut{Uma sequência $S_{best} \subseteq C$ tal que atende as restrições do problema e seja máxima}

$U \gets $ \GENERATEALLSOLUTIONS{$C$}\;
$max \gets 0$\;
$S_{best} \gets \emptyset$\;
\For{\textbf{each} $S$ \textbf{in} $U$} {
   \If{\ISVALID{$S$}}{
   		\If{$S.legth() > max$}{
   		     $max \gets S.legth()$\;
   		     $S_{best} \gets S$\;
   		
   		}
   
   }
}
\Return{$S_{best}$}\;
\caption{{\sc BRUTE-FORCE} encontra a solução ótima listando todas elas.}
\label{algo:brute_force}
\end{algorithm}

\subsubsection{Análise de Complexidade}
\label{subsubsec:fb_analise_complexidade}

Conforme exposto anteriormente, na abordagem de Força Bruta é realizada uma busca em cada item do espaço de soluções do problema. Na subseção \ref{subsubsec:model_fb} discutiu-se que este espaço de solução $O(2^{n})$. Neste contexto, o método responsável por varrer o espaço de soluções necessariamente terá sua complexidade igual $O(2^{n})$. No algoritmo \ref{algo:brute_force} este trabalho é realizado pelo método \textsc{GENERATE-ALL-SOLUTIONS}{}. Como as demais funções do algoritmo possuem complexidade inferiores, podemos concluir que o algoritmo de força bruta proposto possui ondem de complexidade de tempo igual a $O(2^{n})$.

No tocante a complexidade de espaço, o algoritmo necessita carregar os conjuntos $C$, $P$ e $Q$ a fim de poder gerar todas as soluções e verificar se elas são válidas. Apesar de no pior caso existir $O(2^{n})$ possíveis soluções, o sistema apenas armazena a melhor solução encontrada no momento. Partindo desta estratégia teremos um custo de espaço igual a $O(1)$. Neste sentido, o algoritmo têm uma complexidade de espaço igual a $O(n)${}.

\subsection{Uma abordagem Gulosa}
\label{subsec:guloso}

Apesar do algoritmo de força bruta resolver o problema, conforme poderá ser observado na Seção \ref{sec:experimentos} onde descreve a análise experimental dos algoritmos, tal abordagem torna-se impraticável quando o tamanho da entrada cresce. Com o objetivo de encontrar uma solução de melhor desempenho, esta seção descreve uma solução baseada no paradigma \textit{Guloso}.

\subsubsection{Modelagem}
\label{subsubsec:model_guloso}
Um problema é passível de ser resolvido utilizando a abordagem Gulosa caso ele possua a propriedade da \textit{subestrutura ótima}{}. Um problema é dito ter subestrutura ótima se uma solução ótima pode ser construído de forma eficiente a partir de soluções ótimas de seus subproblemas \cite{Cormen:2009:IAT:1614191}{}. Vamos provar que o problema em  questão possui subestrutura ótima.

Iniciemos, sem perda de generalidade, ordenando o conjunto de entrada $C$ de forma decrescente pelo seu conjunto de pesos $P$. Conforme exposto na Seção \ref{sec:definicao} ao realizarmos a ordenação da entrada conforme proposto, o problema transforma-se em encontrar uma \textit{LIS} no novo conjunto de QI's $Q^{'}$ gerado.

Seja $S_{ij}$ a maior LIS entre os elementos $i$ e $j$ do conjunto  $Q^{'}$, conforme descrito no parágrafo anterior, tal que $1 \leq i \leq (n-1)$ e $i < j$. Desta forma, $S_{1n}$ é a solução ótima para o problema. Suponha que escolhamos um valor $k$ qualquer de modo que $ i \leq k < j$. As soluções $S_{ik}$ e $S_{(K+1)j}$ \textit{são ótimas} o que pode ser provado por absurdo. Suponha sem perda de generalidade que exista uma solução $S'_{ik}$ tal $|S'_{ik}| > |S_{ik}|$, a existência de $S'_{ik}$ vai contra a suposição de que $S_{ij}$ seja ótima.

Após provado que o problema apresenta subestrutura ótima já é possível propor um algoritmo guloso para o problema. A solução proposta é detalhada na subseção \ref{subsubsec:alg_guloso}.

\subsubsection{O Algoritmo Guloso}
\label{subsubsec:alg_guloso}

O \textit{Patience Sorting} é um algoritmo de ordenação baseado no jogo de cartas de mesmo nome. O funcionamento básico do jogo é descrito a seguir:

\begin{enumerate}
  \item Inicialmente, não há pilhas. A primeira carta formará uma nova pilha de tamanho 1.
  \item A cada nova carta retirada do baralho, caso ela seja menor que alguma carta no topo de qualquer uma das pilhas disponíveis, a carta será colocada no topo da pilha; caso contrário uma nova pilha será criada.
  \item Quando não há mais cartas no baralho, o jogo termina.
\end{enumerate}

A Figura \ref{fig:patiente_sort} exibe o resultado da aplicação do Patience Sorting em um conjunto de números. Conforme pode ser observado ao final do algoritmo cada pilha terá uma \textit{sequência decrescente}. Utilizando esta propriedade do algoritmo foi realizada uma versão modificada do algoritmo para resolver o problema proposto neste trabalho. Basicamente realiza-se a ordenação do conjunto $P$ de forma crescente; a partir do novo conjunto $Q^{'}$ resultante aplica-se uma versão gulosa do Patience Sorting de que modo que ao final a maior pilha gerada será a solução do problema. O Algoritmo apresenta de forma genérica a solução proposta.

\begin{figure}[ht]
\centering
\includegraphics[width=.5\textwidth]{patiente_sort.jpg}
\caption{O resultado da aplicação Patience Sorting}
\label{fig:patiente_sort}
\end{figure}


\begin{algorithm}
\SetKwFunction{SORT}{SORT}
\SetKwFunction{INITIALIZE}{INITIALIZE}
\SetKwFunction{GREEDYCHOICE}{GREEDY-CHOICE}
\SetKwFunction{PUSH}{PUSH}
\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\KwIn{As sequências finitas $C=\langle c_1, c_2, \ldots, c_n\rangle$, $P=\langle p_1, p_2, \ldots, p_n\rangle$ e $Q=\langle q_1, q_2, \dots, q_n\rangle$}
\KwOut{Uma sequência $S_{best} \subseteq C$ tal que atende as restrições do problema e seja máxima}

\INITIALIZE o conjunto de $n$ pilhas ${S_1,S_2,\ldots,S_n}$\;
\SORT($C$) {//\textit{Ordenando pelos pesos}}\;
$maxLength \gets 0$\;
$bestStack \gets 0$\;
\For{$i$ \textbf{to} $n$} {
   $j \gets $ \GREEDYCHOICE($c_i,q_i$)\;
   \PUSH($S_j,c_i$)\;
   \If{$|S_j| > maxLength$}{
   
   		$maxLength \gets|S_j|$\;
		$bestStack \gets j$\; 
   }   
}
\Return{$S_{bestStack}$}\;
\caption{\sc GREEDY encontra a solução de forma gulosa.}
\label{algo:guloso}
\end{algorithm}

Conforme exposto o algoritmo \ref{algo:guloso} é uma modificação gulosa do Patience Sorting. A parte gulosa do algoritmo está no método \textsc{\GREEDYCHOICE($c_i,q_i$)} que consiste basicamente em buscar a pilha cujo elemento no topo seja maior do que $q_i$. Caso exista mais de uma pilha candidata será \textit{retornada aquela cujo o elemento no topo seja o maior}.

Não obstante, cabe um questionamento se a solução gulosa aqui proposta leva à solução ótima. Seja $G$ uma solução de tamanho $k$ obtida utilizado o algoritmo guloso ora proposto. Se $G$ não for ótima, existe uma solução $\mathcal{O}$ de tamanho $m$ tal que $m > k${}. Suponha ainda, sem perda de generalidade, que em ambas as soluções houve a ordenação dos pesos, cabendo analisar apenas a maior lista decrescente de QI's. Como $m > k$ temos que existe um cérebro $o_{j+1}$ em $\mathcal{O}$ tal que é menor do que o cérebro $g_{j}$ em $G$\footnote{O índice j representa a posição do cérebro na solução}. Contudo, o algoritmo \ref{algo:guloso} realiza a interação sobre \textit{todos} os cérebros e ao final sempre retorna a \textit{maior pilha}{}. Logo, não é possível existir uma sequência decrescente maior do que $G$, logo a solução é ótima.


\subsubsection{Análise de Complexidade}
\label{subsubsec:greedy_analise_complexidade}

Como pode ser observado no Algoritmo \ref{algo:guloso}, a solução gulosa proposta faz uma iteração sobre todos os elementos de entrada. Para cada entrada ele faz uma chamada para o método \textsc{\GREEDYCHOICE($c_i,q_i$)}{}. Este método realiza uma \textit{busca sequencial} para encontrar a pilha no qual o item será inserido, desta forma a complexidade do \textsc{\GREEDYCHOICE} é $O(n)$. Tendo em vista que o método é chamando $n$ vezes podemos concluir que a complexidade do algoritmo guloso é $O(n^{2})$. Cabe ressaltar que existe a possibilidade de melhoria do algoritmo proposto ao implementar o método \textsc{\GREEDYCHOICE} através de busca binária. Neste caso o algoritmo teria a complexidade de $O(nlogn)$.

No que tange ao espaço utilizado o algoritmo necessitará armazenar os conjuntos $C$, $P$ e $Q$. Além disso, no pior caso, será necessário criar um total de $n$ pilhas. Todavia, mesmo no pior caso, a ordem de complexidade de espaço será $O(n)$, ou seja, proporcional ao tamanho da entrada.

\subsection{Programação Dinâmica}
\label{subsec:pd}

A \textit{Programação Dinâmica} é aplicável em problemas que otimização que apresentem as seguintes características: $(i)$ \textit{subestrutura ótima} e $(ii)$ \textit{sobreposição de subproblemas}. A substrutura ótima do problema foi provado na subseção \ref{subsubsec:model_guloso}. Provaremos na próxima subseção que existe sobreposição entre os subproblemas.


\subsubsection{Sobreposição de Subproblemas}
\label{subsubsec:sobreposicao}

De forma análoga as outras soluções propostas neste trabalho, iniciemos que a entrada foi ordenada pelos pesos de forma crescente. Neste sentido, o problema se resume em encontrar uma \textit{LIS} para o novo conjunto $Q^{'}$ de QI's gerado. Seja $LIS(i)$ a maior subsequencia crescente que termina no elemento $i$ do conjunto $Q^{'}$. $L(i)$ pode ser definido recursivamente conforme Equação \ref{eq_lis}{}.


\begin{equation} \label{eq_lis}
LIS(x)=\begin{cases}
               1 + MAX(LIS(j)) \textrm{ onde }j < i \textrm{ e } q_{j} < q_{i}\\
               1 \textrm{ caso contrário }
       \end{cases}
\end{equation}

Para encontramos uma LIS em um conjunto de tamanho $n$ devemos encontrar o $MAX(L(1),L(2),\ldots,L(n)$. A figura \ref{fig:sobreposicao} apresenta a árvore de recursão para o cálculo da LIS para a entrada $ A = \langle1,2,3,4\rangle$. Como pode ser observado existem sobreposições dos subproblemas. 

\begin{figure}[ht]
\centering
\includegraphics[width=.7\textwidth]{sobreposicao.eps}
\caption{Arvore de recursão do LIS para a entrada $A$ }
\label{fig:sobreposicao}
\end{figure}

\subsubsection{O Algoritmo de Programação Dinâmica}
\label{subsubsec:alg:pd}

O algoritmo via Programação Dinâmica proposto utilizou a abordagem de cima para baixo com memoização, ou seja, realiza o calculo para subproblemas menores de modo que estas soluções sejam aproveitadas por subproblemas maiores. O Algoritmo \ref{algo:pd} exibe o código proposto:

\begin{algorithm}
\SetKwFunction{SORT}{SORT}
\SetKwFunction{BUILDSOLUTION}{BUILD-SOLUTION}
\SetKwFunction{INITIALIZE}{INITIALIZE}
\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead
\KwIn{As sequências finitas $C=\langle c_1, c_2, \ldots, c_n\rangle$, $P=\langle p_1, p_2, \ldots, p_n\rangle$ e $Q=\langle q_1, q_2, \dots, q_n\rangle$ e $n$ como tamanho da entrada}
\KwOut{Uma sequência $S_{best} \subseteq C$ tal que atende as restrições do problema e seja máxima}

\SORT($C$) {//\textit{Ordenando pelos pesos}}\;
$maxLength \gets 0$\;
$bestEnd \gets 0$\;
\INITIALIZE $MEMO$ com o valor $0${ //\textit{MEMO é vetor que memoria o resultado de soluções menores}}\;
\INITIALIZE	$PREV$ com o valor $-1${ //\textit{PREV armazena os índices da melhor solução}}\;
\For{$i \gets 1$ \textbf{to} $(n-1)$} {
	\For{$j \gets (i-1)$ \textbf{to} $0$} {
		\If{$q_j < q_i$ \textbf{and} $MEMO[i] < MEMO[j]$}{
		
			$MEMO[i] \gets MEMO[j] + 1$\;
		    $PREV[i] \gets j$\;	
		}
    
	}
	
	\If ($MEMO[i] > maxLength$) {
			$bestEnd = i$\;
			$maxLength = memo[i]$\;
		}
    
}

$S \gets$ \BUILDSOLUTION($PREV,n$)\;

\Return{$S$}\;
\caption{\sc PROGRAMAÇÃO DINÂMICA de cima para baixo com memoização}
\label{algo:pd}
\end{algorithm}

O vetor \textsc{MEMO} armazena os resultados dos subproblemas a fim de serem utilizados pelos subproblemas menores. Para cada $i$ é armazenado no vetor \textsc{PREV}{} os índices das maiores LIS encontrada de modo a solução ser construída através do método \textsc{BUILD-SOLUTION}.

\subsubsection{Análise da Complexidade}
\label{subsubsec:analise_pg}

Analisando o pseudocódigo do Algoritmo \ref{algo:pd} verificamos que ele possui dois loop aninhados. Dentro do loop mais interno apenas existem operações de complexidade $O(1)$. Desta forma, o algoritmo possui complexidade igual a $O(n^{2})$. No que tange ao espaço utilizado, o algoritmo utiliza de dois vetores para armazenarem os dados de soluções menores e dos índices da LIS. Neste sentido a sua complexidade de espaço é da ordem de $O(n)$. O algoritmo poderia ser otimizado em loop interno de modo a encontrar os valores armazenados em $O(log(n))$ resultado em uma complexidade igual à $O(nlogn)$

\section{Análise Experimental}
\label{sec:experimentos}

Com o objetivo de verificar a desempenho real das soluções propostas foi realizada uma bateria de testes. Os testes consistem em executar os algoritmos em conjunto de entradas de diferentes tamanhos com a medição dos respetivos tempos de execução. Os testes foram executados em computador com o sistema operacional Ubuntu versão 12.04 kernel 3.13.0-37-generic 64 bits e com 4GB de memória RAM. Os tempos de executam consistem da média de cinco execuções para cada entrada.

A bateria de testes foi executada prioritariamente nos algoritmos guloso e programação dinâmica tendo em vista que para algumas entradas o algoritmo de força bruta não foi possível executar. Os tamanho de entrada para o qual o força bruta executou são exibidos na Tabela \ref{tab:dados_fb}{}.

\begin{table}[!t]

\renewcommand{\arraystretch}{1.3}
\label{tab:dados_fb}
\caption{Tempo de execução do algoritmo de força bruta}
\centering
\resizebox{.5\linewidth}{!}{
\begin{tabular}{|c|c|}
\hline 
\rule[-1ex]{0pt}{2.5ex} \textbf{Tamanho Entrada} & \textbf{Tempo Execução (s)}\\
\hline 
\rule[-1ex]{0pt}{2.5ex} 5 & 1\\ 
\hline
\rule[-1ex]{0pt}{2.5ex} 9 & 1620\\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} 10 & 3618\\ 
\hline 
\rule[-1ex]{0pt}{2.5ex} 50 & 7250\\ 
\hline 
\end{tabular} 
}	
\end{table}

Os tamanhos de entrada (eixo x) e tempo de execução (eixo y) são exibidos na Figura \ref{fig:dados_greedy_pg}. Como pode ser observado o tempo de execução de ambos os algoritmos são similares para entradas menores. Quando o tamanho da entrada cresce verifica-se que o algoritmo guloso é mais eficiente. Esta diferença pode ser devido ao fato do algoritmo guloso executar em média um número menor de operações que seu concorrente.


\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{plot_greedy_pd.eps}
\caption{Tempos de execução Greedy vs PG}
\label{fig:dados_greedy_pg}
\end{figure}

A figura \ref{fig:tamanho_solucoes} exibe o tamanho da solução encontrada para uma determinada entrada. Naturalmente o numero de elementos da solução é proporcional ao tamanho da entrada, todavia, é possível verificar que é cada mais difícil encontrar indivíduos que atendam aos requisitos do problema. Por exemplo para uma entrada de tamanho 50, existem 18\% de indivíduos que atendem ao requisito do problema, todavia, para uma entrada de tamanho 1000 o percentual cai para 3\%{}.

\begin{figure}[ht]
\centering
\includegraphics[width=0.9\textwidth]{tamanho_solucoes.eps}
\caption{Tempos de execução Greedy vs PG}
\label{fig:tamanho_solucoes}
\end{figure}


\section{Conclusões}
\label{sec:conclusao}

Este trabalho se propôs a resolver o problema de encontrar o maior número de pessoas em determinada população cujo peso do cérebro seja menor, contudo, apresentando um maior QI. Afim de resolver o problema foram propostos três algoritmos utilizando os paradigmas Força Bruta, Guloso e Programação Dinâmica. O algoritmo de Força Bruta, apesar de garantidamente retornar a solução ótima, mostrou-se inutilizável quando o tamanho das entradas foram crescendo. Para os paradigmas Guloso e Programação Dinâmica provou-se que o problema atendia aos requisitos de subestrutura ótima e sobreposição de subproblemas (necessário à Programação Dinâmica). Foi possível mostrar que os algoritmos resultam em soluções ótimas. A partir deste trabalho foi possível verificar a aplicação dos diferentes paradigmas de programação em um mesmo problema e como as especificidades de cada paradigma levam as diferentes soluções.

\bibliographystyle{sbc}
\bibliography{sbc-template}

\end{document}
